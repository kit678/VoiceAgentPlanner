import asyncio
import os
from dotenv import load_dotenv
from loguru import logger

from pipecat.frames.frames import Frame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.transports.local.audio import LocalAudioTransport, LocalAudioTransportParams
from pipecat.services.google.stt import GoogleSTTService
from pipecat.services.google.tts import GoogleTTSService
from pipecat.services.gemini_multimodal_live.gemini import (
    GeminiMultimodalLiveLLMService,
    InputParams as GeminiInputParams, # Renamed to avoid conflict
    GeminiMultimodalModalities
)
from pipecat.transcriptions.language import Language
from pipecat.observers.loggers.transcription_log_observer import TranscriptionLogObserver

# Import custom processors and function schemas from the main pipecat_pipeline_functions
# Assuming pipecat_pipeline_functions.py is in src/, and this file is in src/llm/
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..')) # Add src to path

from pipecat_pipeline_functions import (
    WebSocketBridgeProcessor,
    AudioGateProcessor,
    create_function_schemas,
    TaskFunctions, 
    ReminderFunctions, 
    TimerFunctions, 
    NoteFunctions, 
    GoalFunctions, 
    ContextFunctions
)
from websocket_server import PipecatWebSocketBridge, start_websocket_bridge

load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '../../../.env'), override=True)

# Remove the problematic line that's causing the error
# logger.remove(0)
logger.add(sys.stderr, level="DEBUG")

class VoicePipeline:
    def __init__(self):
        logger.info("Initializing VoicePipeline...")
        # Initialize WebSocket Bridge
        self.ws_bridge = PipecatWebSocketBridge()

        # Initialize custom processors
        self.audio_gate = AudioGateProcessor()
        # Use the WebSocketBridgeProcessor without passing bridge_instance
        self.ws_processor = WebSocketBridgeProcessor()
        # Link the ws_processor's text handler to the ws_bridge
        self.ws_bridge._text_input_handler = self.ws_processor.handle_text_from_ui

        # Initialize services
        self.stt = GoogleSTTService()
        self.tts = GoogleTTSService()

        # Create function schemas and tools
        # The create_function_schemas function doesn't take any arguments
        # Create function schemas and implementations
        # function_schemas, function_impls = create_function_schemas()
        # tools_schema = function_impls.get_tools_schema()
        tools_schema, _ = create_function_schemas() # Directly use the returned ToolsSchema

        # GEMINI SERVICE with Function Calling
        self.llm = GeminiMultimodalLiveLLMService(
            project_id=os.getenv("GOOGLE_PROJECT_ID"),
            location=os.getenv("GOOGLE_LOCATION"),
            model="gemini-1.5-flash",
            input_params=GeminiInputParams(
                language_code=Language.EN_US,
                modalities=[GeminiMultimodalModalities.SPEECH_TO_TEXT]
            ),
            tools=[tools_schema]
        )

        # Create audio transport
        self.audio_transport = LocalAudioTransport(
            params=LocalAudioTransportParams(
                mic_enabled=True,
                speaker_enabled=True,
                camera_enabled=False,
                vad_enabled=True,
                vad_audio_passthrough=True
            )
        )

        # Create pipeline
        self.pipeline = Pipeline([
            self.audio_transport.source(),
            self.audio_gate,
            self.stt,
            self.llm,
            self.ws_processor, # WebSocket processor after LLM
            self.tts,
            self.audio_transport.sink(),
        ])
        self.pipeline.add_observer(TranscriptionLogObserver())
        
        # Set the pipeline reference in the WebSocket bridge
        self.ws_bridge.set_pipeline(self) # Pass self (VoicePipeline) which has audio_gate
        # Also set the audio_gate directly if needed by ws_bridge for start/stop listening
        # This assumes ws_bridge.pipecat_pipeline.audio_gate will be used.

        # Create runner
        self.runner = PipelineRunner()
        logger.info("VoicePipeline initialized.")

    async def start(self):
        """Start the pipeline and WebSocket server"""
        logger.info("Starting VoicePipeline and WebSocket server...")
        # Start WebSocket server in a separate task
        websocket_server_task = asyncio.create_task(start_websocket_bridge(self.ws_bridge))
        
        # Start the Pipecat pipeline
        pipeline_task = PipelineTask(
            self.pipeline,
            params=PipelineParams(allow_interruptions=True, enable_turn_taking=True)
        )
        
        try:
            await self.runner.run(pipeline_task)
        except KeyboardInterrupt:
            logger.info("Pipeline stopped by user.")
        except Exception as e:
            logger.error(f"Pipeline error: {e}")
        finally:
            logger.info("Shutting down...")
            if not websocket_server_task.done():
                websocket_server_task.cancel()
                try:
                    await websocket_server_task
                except asyncio.CancelledError:
                    logger.info("WebSocket server task cancelled.")
            logger.info("VoicePipeline stopped.")